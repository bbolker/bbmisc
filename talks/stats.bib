
@article{davies_dont_2015,
	title = {Don't let spurious accusations of pseudoreplication limit our ability to learn from natural experiments (and other messy kinds of ecological monitoring)},
	copyright = {© 2015 The Authors. Ecology and Evolution published by John Wiley \& Sons Ltd., This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.},
	issn = {2045-7758},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/ece3.1782/abstract},
	doi = {10.1002/ece3.1782},
	abstract = {Pseudoreplication is defined as the use of inferential statistics to test for treatment effects where treatments are not replicated and/or replicates are not statistically independent. It is a genuine but controversial issue in ecology particularly in the case of costly landscape-scale manipulations, behavioral studies where ethics or other concerns may limit sample sizes, ad hoc monitoring data, and the analysis of natural experiments where chance events occur at a single site. Here key publications on the topic are reviewed to illustrate the debate that exists about the conceptual validity of pseudoreplication. A survey of ecologists and case studies of experimental design and publication issues are used to explore the extent of the problem, ecologists’ solutions, reviewers’ attitudes, and the fate of submitted manuscripts. Scientists working across a range of ecological disciplines regularly come across the problem of pseudoreplication and build solutions into their designs and analyses. These include carefully defining hypotheses and the population of interest, acknowledging the limits of statistical inference and using statistical approaches including nesting and random effects. Many ecologists face considerable challenges getting their work published if accusations of pseudoreplication are made – even if the problem has been dealt with. Many reviewers reject papers for pseudoreplication, and this occurs more often if they haven't experienced the issue themselves. The concept of pseudoreplication is being applied too dogmatically and often leads to rejection during review. There is insufficient consideration of the associated philosophical issues and potential statistical solutions. By stopping the publication of ecological studies, reviewers are slowing the pace of ecological research and limiting the scope of management case studies, natural events studies, and valuable data available to form evidence-based solutions. Recommendations for fair and consistent treatment of pseudoreplication during writing and review are given for authors, reviewers, and editors.},
	language = {en},
	urldate = {2015-11-08},
	journal = {Ecology and Evolution},
	author = {Davies, G. Matt and Gray, Alan},
	month = oct,
	year = {2015},
	keywords = {Bayesian statistics, confounded effects, hypothesis formation, nesting, peer review, P-values, random effects, scientific publication, statistical population}
}

@article{hurlbert_pseudoreplication_1984,
	title = {Pseudoreplication and the Design of Ecological Field Experiments},
	volume = {54},
	issn = {0012-9615},
	url = {http://www.esajournals.org/doi/abs/10.2307/1942661},
	doi = {10.2307/1942661},
	abstract = {Pseudoreplication is defined as the use of inferential statistics to test for treatment effects with data from experiments where either treatments are not replicated (though samples may be) or replicates are not statistically independent. In ANOVA terminology, it is the testing for treatment effects with an error term inappropriate to the hypothesis being considered. Scrutiny of 176 experimental studies published between 1960 and the present revealed that pseudoreplication occurred in 27\% of them, or 48\% of all such studies that applied inferential statistics. The incidence of pseudoreplication is especially high in studies of marine benthos and small mammals. The critical features of controlled experimentation are reviewed. Nondemonic intrusion is defined as the impingement of chance events on an experiment in progress. As a safeguard against both it and preexisting gradients, interspersion of treatments is argued to be an obligatory feature of good design. Especially in small experiments, adequate interspersion can sometimes be assured only by dispensing with strict randomization procedures. Comprehension of this conflict between interspersion and randomization is aided by distinguishing pre—layout (or conventional) and layout—specific alpha (probability of type I error). Suggestions are offered to statisticians and editors of ecological journals as to how ecologists' understanding of experimental design and statistics might be improved.  See full-text article at JSTOR},
	number = {2},
	urldate = {2015-11-08},
	journal = {Ecological Monographs},
	author = {Hurlbert, Stuart H.},
	month = jun,
	year = {1984},
	pages = {187--211},
	file = {Snapshot:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/5Z5X68SZ/1942661.html:text/html}
}

@article{student_errors_1927,
	title = {Errors of Routine Analysis},
	volume = {19},
	copyright = {Copyright © 1927 Biometrika Trust},
	issn = {0006-3444},
	url = {http://www.jstor.org/stable/2332181},
	doi = {10.2307/2332181},
	number = {1/2},
	urldate = {2015-11-08},
	journal = {Biometrika},
	author = {{Student}},
	month = jul,
	year = {1927},
	pages = {151--164}
}

@article{gelman_beyond_2014,
	title = {Beyond Power Calculations: Assessing Type {S} (Sign) and Type {M} (Magnitude) Errors},
	volume = {9},
	issn = {1745-6916, 1745-6924},
	url = {http://pps.sagepub.com/content/9/6/641},
	doi = {10.1177/1745691614551642},
	abstract = {Statistical power analysis provides the conventional approach to assess error rates when designing a research study. However, power analysis is flawed in that a narrow emphasis on statistical significance is placed as the primary focus of study design. In noisy, small-sample settings, statistically significant results can often be misleading. To help researchers address this problem in the context of their own studies, we recommend design calculations in which (a) the probability of an estimate being in the wrong direction (Type S [sign] error) and (b) the factor by which the magnitude of an effect might be overestimated (Type M [magnitude] error or exaggeration ratio) are estimated. We illustrate with examples from recent published research and discuss the largest challenge in a design calculation: coming up with reasonable estimates of plausible effect sizes based on external information.},
	language = {en},
	number = {6},
	urldate = {2015-11-08},
	journal = {Perspectives on Psychological Science},
	author = {Gelman, Andrew and Carlin, John},
	month = nov,
	year = {2014},
	pmid = {26186114},
	keywords = {design calculation, exaggeration ratio, power analysis, replication crisis, statistical significance, Type M error, Type S error},
	pages = {641--651},
	file = {Full Text PDF:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/HQW2F8VX/Gelman and Carlin - 2014 - Beyond Power Calculations Assessing Type S (Sign) .pdf:application/pdf;Snapshot:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/4QM77D73/641.html:text/html}
}


@article{simmons_false-positive_2011,
	title = {False-Positive Psychology: Undisclosed Flexibility  in Data Collection and Analysis Allows Presenting Anything as Significant},
	volume = {22},
	issn = {0956-7976, 1467-9280},
	url = {http://pss.sagepub.com/content/22/11/1359},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2015-11-08},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	pmid = {22006061},
	keywords = {disclosure, methodology, motivated reasoning, publication},
	pages = {1359--1366},
	file = {Full Text PDF:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/TNSUZHFS/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility .pdf:application/pdf;Snapshot:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/BATW66XJ/1359.html:text/html}
}


@article{gelman_difference_2006,
	title = {The Difference Between "Significant" and "Not Significant" is not Itself Statistically Significant},
	volume = {60},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649},
	doi = {10.1198/000313006X152649},
	language = {en},
	number = {4},
	urldate = {2015-11-10},
	journal = {The American Statistician},
	author = {Gelman, Andrew and Stern, Hal},
	month = nov,
	year = {2006},
	pages = {328--331},
	file = {signif4.pdf:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/I64MSHDR/signif4.pdf:application/pdf}
}


@article{mccullough_accuracy_2008,
	title = {On the accuracy of statistical procedures in {Microsoft} {Excel} 2007},
	volume = {52},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947308001606},
	doi = {10.1016/j.csda.2008.03.004},
	abstract = {Excel 2007, like its predecessors, fails a standard set of intermediate-level accuracy tests in three areas: statistical distributions, random number generation, and estimation. Additional errors in specific Excel procedures are discussed. Microsoft’s continuing inability to correctly fix errors is discussed. No statistical procedure in Excel should be used until Microsoft documents that the procedure is correct; it is not safe to assume that Microsoft Excel’s statistical procedures give the correct answer. Persons who wish to conduct statistical analyses should use some other package.},
	number = {10},
	urldate = {2015-11-10},
	journal = {Computational Statistics \& Data Analysis},
	author = {McCullough, B. D. and Heiser, David A.},
	month = jun,
	year = {2008},
	pages = {4570--4578},
	file = {ScienceDirect Snapshot:/Users/bolker/Library/Application Support/Firefox/Profiles/rxerw03y.default/zotero/storage/HWCKWBSJ/S0167947308001606.html:text/html}
}



@article{murtaugh_simplicity_2007,
	title = {Simplicity and {Complexity} in {Ecological} {Data} {Analysis}},
	volume = {88},
	url = {http://www.esajournals.org/doi/abs/10.1890/0012-9658%282007%2988%5B56%3ASACIED%5D2.0.CO%3B2},
	number = {1},
	journal = {Ecology},
	author = {Murtaugh, Paul A},
	year = {2007},
	pages = {56--62}
}

@incollection{crome_researching_1997,
	address = {Chicago, IL},
	title = {Researching tropical forest fragmentation: {Shall} we keep on doing what we're doing?},
	booktitle = {Tropical forest remnants: ecology, management, and conservation of fragmented communities},
	publisher = {University of Chicago Press},
	author = {Crome, Francis H. J.},
	editor = {Laurance, W. F and Bierregard, R. O},
	year = {1997},
	pages = {485--501}
}


@article{hurlbert_pseudoreplication_1984,
	title = {Pseudoreplication and the {Design} of {Ecological} {Field} {Experiments}},
	volume = {54},
	journal = {Ecological Monographs},
	author = {Hurlbert, S.},
	year = {1984},
	pages = {187--211}
}


@article{hurlbert_misinterpretations_2004,
	title = {On misinterpretations of pseudoreplication and related matters: a reply to {Oksanen}},
	volume = {104},
	issn = {00301299},
	shorttitle = {{\textless}title xmlns="http},
	url = {http://doi.wiley.com/10.1111/j.0030-1299.2004.12752.x},
	doi = {10.1111/j.0030-1299.2004.12752.x},
	number = {3},
	urldate = {2010-12-04},
	journal = {Oikos},
	author = {Hurlbert, Stuart H.},
	month = mar,
	year = {2004},
	pages = {591--597}
}

@article{cottenie_comment_2003,
	title = {Comment to {Oksanen} (2001): reconciling {Oksanen} (2001) and {Hurlbert} (1984)},
	volume = {100},
	number = {2},
	journal = {Oikos},
	author = {Cottenie, K. and De Meester, L.},
	year = {2003},
	pages = {394--396}
}

@article{oksanen_logic_2001,
	title = {Logic of {Experiments} in {Ecology}: {Is} {Pseudoreplication} a {Pseudoissue}?},
	volume = {94},
	issn = {00301299},
	shorttitle = {Logic of {Experiments} in {Ecology}},
	url = {http://www.jstor.org.lp.hscl.ufl.edu/stable/3547252},
	abstract = {Hurlbert divides experimental ecologist into 'those who do not see any need for dispersion (of replicated treatments and controls), and those who do recognize its importance and take whatever measures are necessary to achieve a good dose of it'. Experimental ecologists could also be divided into those who do not see any problems with sacrificing spatial and temporal scales in order to obtain replication, and those who understand that appropriate scale must always have priority over replication. If an experiment is conducted in a spatial or temporal scale, where the predictions of contesting hypotheses are convergent or ambiguous, no amount of technical impeccability can make the work instructive. Conversely, replication can always be obtained afterwards, by conducting more experiments with basically similar design in different areas and by using meta-analysis. This approach even reduces the sampling bias obtained if resources are allocated to a small number of well-replicated experiments. For a strict advocate of the hypothetico-deductive method, replication is unnecessary even as a matter of principle, unless the predicted response is so weak that random background noise is a plausible excuse for a discrepancy between predictions and results. By definition, a prediction is an 'all-statement', referring to all systems within a well-defined category. What applies to all must apply to any. Hence, choosing two systems and assigning them randomly to a treatment and a control is normally an adequate design for a deductive experiment. The strength of such experiments depends on the firmness of the predictions and their a priori probability of corroboration. Replication is but one of many ways of reducing this probability. Whether the experiment is replicated or not, inferential statistics should always be used, to enable the reader to judge how well the apparent patterns in samples reflect real patterns in statistical populations. The concept 'pseudoreplication' amounts to entirely unwarranted stigmatization of a reasonable way to test predictions referring to large-scale systems.},
	number = {1},
	urldate = {2009-09-17},
	journal = {Oikos},
	author = {Oksanen, Lauri},
	month = jul,
	year = {2001},
	note = {ArticleType: primary\_article / Full publication date: Jul., 2001 / Copyright © 2001 Nordic Society Oikos},
	pages = {27--38}
}


@article{lavine_living_2010,
	title = {Living dangerously with big fancy models},
	volume = {91},
	issn = {0012-9658},
	url = {http://www.esajournals.org/doi/abs/10.1890/10-1124.1},
	doi = {10.1890/10-1124.1},
	number = {12},
	urldate = {2013-11-28},
	journal = {Ecology},
	author = {Lavine, Michael},
	month = dec,
	year = {2010},
	keywords = {Bayesian analysis, chronic wasting disease, Epidemiology, frailty, Hierarchical models, Markov Chain Monte Carlo},
	pages = {3487--3487}
}


@article{dahlgren_alternative_2010,
	title = {Alternative regression methods are not considered in {Murtaugh} (2009) or by ecologists in general},
	volume = {13},
	issn = {1461-0248},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1461-0248.2010.01460.x/abstract},
	doi = {10.1111/j.1461-0248.2010.01460.x},
	abstract = {Ecology Letters (2010) 13: E7–E9 
Abstract
Murtaugh (2009) recently illustrated that all subsets variable selection is very similar to stepwise regression. This, however, does not necessarily mean both methods are useful. On the contrary, the same problems with overfitting should apply. Ecologists should, if model building is indeed necessary, consider more reliable regression methods now available.},
	language = {en},
	number = {5},
	urldate = {2016-04-14},
	journal = {Ecology Letters},
	author = {Dahlgren, Johan P.},
	month = may,
	year = {2010},
	keywords = {AIC, all subsets, BIC, lasso, ridge regression, Shrinkage, stepwise multiple regression, Variable selection},
	pages = {E7--E9},
	file = {Snapshot:/home/bolker/.mozilla/firefox/f2nw6467.default/zotero/storage/ZKQHERDI/abstract.html:text/html}
}


@book{kery_introduction_2010,
	address = {Amsterdam; Boston},
	title = {Introduction to {WinBUGS} for ecologists {Bayesian} approach to regression, {ANOVA}, mixed models and related analyses},
	isbn = {978-0-12-378605-0 0-12-378605-3 0-12-378606-1 978-0-12-378606-7 1-282-75566-8 978-1-282-75566-6},
	abstract = {Bayesian statistics has exploded into biology and its sub-disciplines such as ecology over the past decade. The free software program WinBUGS and its open-source sister OpenBugs is currently the only flexible and general-purpose program available with which the average ecologist can conduct their own standard and non-standard Bayesian statistics. Introduction to WINBUGS for Ecologists goes right to the heart of the matter by providing ecologists with a comprehensive, yet concise, guide to applying WinBUGS to the types of models that they use most often: linear (LM), generalized linear (GLM), linear mixed (LMM) and generalized linear mixed models (GLMM). Introduction to WinBUGS for Ecologists combines the use of simulated data sets "paired" analyses using WinBUGS (in a Bayesian framework for analysis) and in R (in a frequentist mode of inference) and uses a very detailed step-by-step tutorial presentation style that really lets the reader repeat every step of the application of a given mode in their own research. - Introduction to the essential theories of key models used by ecologists - Complete juxtaposition of classical analyses in R and Bayesian Analysis of the same models in WinBUGS - Provides every detail of R and WinBUGS code required to conduct all analyses - Written with ecological language and ecological examples - Companion Web Appendix that contains all code contained in the book, additional material (including more code and solutions to exercises) - Tutorial approach shows ecologists how to implement Bayesian analysis in practical problems that they face.},
	language = {English},
	publisher = {Elsevier},
	author = {Kéry, Marc},
	year = {2010}
}


@book{hobbs_bayesian_2015,
	address = {Princeton, New Jersey},
	title = {Bayesian {Models}: {A} {Statistical} {Primer} for {Ecologists}},
	isbn = {978-0-691-15928-7},
	shorttitle = {Bayesian {Models}},
	abstract = {Bayesian modeling has become an indispensable tool for ecological research because it is uniquely suited to deal with complexity in a statistically coherent way. This textbook provides a comprehensive and accessible introduction to the latest Bayesian methods—in language ecologists can understand. Unlike other books on the subject, this one emphasizes the principles behind the computations, giving ecologists a big-picture understanding of how to implement this powerful statistical approach.Bayesian Models is an essential primer for non-statisticians. It begins with a definition of probability and develops a step-by-step sequence of connected ideas, including basic distribution theory, network diagrams, hierarchical models, Markov chain Monte Carlo, and inference from single and multiple models. This unique book places less emphasis on computer coding, favoring instead a concise presentation of the mathematical statistics needed to understand how and why Bayesian analysis works. It also explains how to write out properly formulated hierarchical Bayesian models and use them in computing, research papers, and proposals.This primer enables ecologists to understand the statistical principles behind Bayesian modeling and apply them to research, teaching, policy, and management.Presents the mathematical and statistical foundations of Bayesian modeling in language accessible to non-statisticiansCovers basic distribution theory, network diagrams, hierarchical models, Markov chain Monte Carlo, and moreDeemphasizes computer coding in favor of basic principlesExplains how to write out properly factored statistical expressions representing Bayesian models},
	language = {English},
	publisher = {Princeton University Press},
	author = {Hobbs, N. Thompson and Hooten, Mevin B.},
	month = aug,
	year = {2015}
}


@article{ioannidis_why_2005,
	title = {Why {Most} {Published} {Research} {Findings} {Are} {False}},
	volume = {2},
	url = {http://dx.doi.org/10.1371/journal.pmed.0020124},
	doi = {10.1371/journal.pmed.0020124},
	abstract = {Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
	number = {8},
	urldate = {2011-04-07},
	journal = {PLoS Med},
	author = {Ioannidis, John P. A.},
	year = {2005},
	pages = {e124}
}


@article{simmons_false-positive_2011,
	title = {False-{Positive} {Psychology} {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976, 1467-9280},
	url = {http://pss.sagepub.com/content/22/11/1359},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2012-05-10},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	keywords = {methodology, motivated reasoning, publication, disclosure},
	pages = {1359--1366}
}


@inproceedings{matejka_datasaurus_2017,
	title = {The {Datasaurus} {Dozen} - {Same} {Stats}, {Different} {Graphs}: {Generating} {Datasets} with {Varied} {Appearance} and {Identical} {Statistics} through {Simulated} {Annealing} {\textbar} {Autodesk} {Research}},
	url = {https://www.autodeskresearch.com/publications/samestats},
	doi = {10.1145/3025453.3025912},
	urldate = {2018-11-14},
	author = {Matejka, Justin and Fitzmaurice, George},
	year = {2017}
}


@article{dushoff_i_2019,
  title = {I Can See Clearly Now: {{Reinterpreting}} Statistical Significance},
  shorttitle = {I Can See Clearly Now},
  author = {Dushoff, Jonathan and Kain, Morgan P. and Bolker, Benjamin M.},
  year = {2019},
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {6},
  pages = {756--759},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13159},
  abstract = {Null hypothesis significance testing (NHST) remains popular despite decades of concern about misuse and misinterpretation. There are many recent suggestions for mitigating problems arising from NHST, including calls for abandoning NHST in favour of Bayesian or information-theoretic approaches. We believe that NHST will continue to be widely used, and can be most usefully interpreted as a guide to whether a certain effect can be seen clearly in a particular context (e.g. whether we can clearly see that a correlation or between-group difference is positive or negative). We believe that much misinterpretation of NHST is due to language: significance testing has little to do with other meanings of the word `significance'. We therefore suggest that researchers describe the conclusions of null-hypothesis tests in terms of statistical `clarity' rather than `significance'. We illustrate our point by rewriting common misinterpretations of the meaning of statistical tests found in the literature using the language of `clarity'. The meaning of statistical tests become easier to interpret and explain when viewed through the lens of `statistical clarity'. Our suggestion is mild, but practical: this simple semantic change could enhance clarity in statistical communication.},
  copyright = {\textcopyright{} 2019 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society},
  langid = {english},
  keywords = {hypothesis testing,null hypothesis significance testing,p-value,statistical clarity,statistical philosophy,statistical significance},
  file = {/home/bolker/Zotero/storage/CAVBL7P7/Dushoff et al. - 2019 - I can see clearly now Reinterpreting statistical .pdf;/home/bolker/Zotero/storage/2XGU7QXI/2041-210X.html}
}


@book{chambers_graphical_1983,
	title = {Graphical methods for data analysis},
	shorttitle = {Graphical methods for data analysis},
	publisher = {Chapman and Hall/CRC},
	author = {Chambers, John M. and Cleveland, William S. and Kleiner, Beat and Tukey, Paul A.},
	year = {2018},
	note = {First published 1983}
}


@article{simmons_false-positive_2011,
	title = {False-{Positive} {Psychology} {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976, 1467-9280},
	url = {http://pss.sagepub.com/content/22/11/1359},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2015-11-08},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	pmid = {22006061},
	keywords = {methodology, motivated reasoning, publication, disclosure},
	pages = {1359--1366}
}

@article{gelman_statistical_2014,
	title = {The statistical crisis in science: data-dependent analysis--a "garden of forking paths"--explains why many statistically significant comparisons don't hold up},
	volume = {102},
	issn = {0003-0996},
	shorttitle = {The statistical crisis in science},
	url = {http://link.galegroup.com/apps/doc/A389260653/AONE?u=ocul_mcmaster&sid=AONE&xid=4f4562c0},
	language = {English},
	number = {6},
	urldate = {2019-01-07},
	journal = {American Scientist},
	author = {Gelman, Andrew and Loken, Eric},
	year = {2014},
	note = {460},
	keywords = {Periodical publishing, Science journals},
	pages = {460--}
}



@article{brice_sampling_2021,
  title = {Sampling Bias Exaggerates a Textbook Example of a Trophic Cascade},
  author = {Brice, Elaine M. and Larsen, Eric J. and MacNulty, Daniel R.},
  year = {2022},
  journal = {Ecology Letters},
  volume = {25},
  number = {1},
  pages = {177--188},
  issn = {1461-0248},
  doi = {10.1111/ele.13915},
  abstract = {Understanding trophic cascades in terrestrial wildlife communities is a major challenge because these systems are difficult to sample properly. We show how a tradition of non-random sampling has confounded this understanding in a textbook system (Yellowstone National Park) where carnivore [Canis lupus (wolf)] recovery is associated with a trophic cascade involving changes in herbivore [Cervus canadensis (elk)] behaviour and density that promote plant regeneration. Long-term data indicate a practice of sampling only the tallest young plants overestimated regeneration of overstory aspen (Populus tremuloides) by a factor of 4–7 compared to random sampling because it favoured plants taller than the preferred browsing height of elk and overlooked non-regenerating aspen stands. Random sampling described a trophic cascade, but it was weaker than the one that non-random sampling described. Our findings highlight the critical importance of basic sampling principles (e.g. randomisation) for achieving an accurate understanding of trophic cascades in terrestrial wildlife systems.},
  langid = {english},
  keywords = {aspen,carnivore,elk,non-random sampling,predator indirect effects,preferred browsing height,sampling bias,trophic cascade,ungulate,wolf},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ele.13915},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ele.13915},
}


@article{ziemannGene2016,
  title = {Gene Name Errors Are Widespread in the Scientific Literature},
  author = {Ziemann, Mark and Eren, Yotam and {El-Osta}, Assam},
  year = {2016},
  month = aug,
  journal = {Genome Biology},
  volume = {17},
  number = {1},
  pages = {177},
  issn = {1474-760X},
  doi = {10.1186/s13059-016-1044-7},
  abstract = {The spreadsheet software Microsoft Excel, when used with default settings, is known to convert gene names to dates and floating-point numbers. A programmatic scan of leading genomics journals reveals that approximately one-fifth of papers with supplementary Excel gene lists contain erroneous gene name conversions.},
  keywords = {Gene symbol,Microsoft Excel,Supplementary data},
  file = {/home/bolker/Zotero/storage/E6IS6LUC/Ziemann et al. - 2016 - Gene name errors are widespread in the scientific .pdf;/home/bolker/Zotero/storage/XLGV8Q49/s13059-016-1044-7.html}
}

