---
title: disaggregating clarity of statistical results
date: today
author: Ben Bolker and Jonathan Dushoff
format:
  html:
    embed-resources: true
    code-fold: true
bibliography: sesoi.bib    
---

(Source code is in [this directory](https://github.com/bbolker/bbmisc/tree/master/Rmisc))

```{r setup, message = FALSE}
library(tidyverse)
library(ggplot2); theme_set(theme_bw() + theme(panel.spacing=grid::unit(0, "lines")))
source("sim_sesoi_funs.R")
```

Simulate a $t$-test-like comparison: what is the distribution of outcomes?

We are classifying outcomes in the following way (from [here](https://dushoff.github.io/ResearchSandbox/clarStrength.Rout.pdf)/[here](https://github.com/dushoff/ResearchSandbox/blob/main/clarStrength.R):

```{r dushoff_effects}
largeEffect=1.3; smallEffect=0.5; tinyEffect = 0.1; smallVar = 0.2; medVar = 0.4; largeVar = 0.7; hugeVar = 1.2
span = 2
vget = Vectorize(get)
vr <- (
	read.table(header=TRUE, strip.white=TRUE, sep=":", text="
		pic : val : unc : atext : ntext
		PL : largeEffect : smallVar : Clearly large|and positive : different
		PU : largeEffect : largeVar : Clearly positive,|maybe large : different
		PS : smallEffect : smallVar : Clearly positive|and not large : different
		US : tinyEffect : medVar : Maybe positive,|clearly small : different
		UU : smallEffect : largeVar : Not both (large|and negative) : different
		nopower : tinyEffect : hugeVar : Should have|done a power|analysis first : different
	")
)
vf <- (vr
	|> mutate(NULL
		, pic = factor(pic, levels=rev(pic))
		, val = vget(val)
		, unc = vget(unc)
		, lwr = val-unc
		, upr = val+unc
		, atext = gsub('\\|', '\n', atext)
	)
)
print(ggplot(vf)
	+ aes(val, pic)
	+ geom_pointrange(aes(xmin=lwr, xmax=upr))
    + theme(panel.grid.minor.x = element_blank())  ## delete vertical grid lines
	+ geom_vline(xintercept=c(0, -1, 1), lty = c(1, 2, 2))
	+ scale_x_continuous(limits=c(-span, span)
		, breaks = -1:1
		, labels = c("cutoff\n(SESOI)", 0 , "cutoff\n(SESOI)")
	)
	+ scale_y_discrete(labels=rev(vf$atext))
  + labs(x = "", y = "")
)
```

As an example, we'll start by determining the sample size to needed to get 80% power for a cutoff/SESOI value (`s` in the underlying code) with a standard deviation of 1:

```{r pow1}
pp <- power.t.test(delta = 1, sd = 1, power = 0.8)
n <- ceiling(pp$n)  ## 17
tt <- power.t.test(delta = 1, sd = 1, n = n)
pow1 <- round(tt$power,3) ## 0.807
```

With per-sample $n$ of `r n` (and with $\delta=1$, $\sigma=1$, $\alpha=0.05$)  we get a power of `r pow1`.

If we simulate 10,000 such experiments, here is the breakdown of different outcomes:

```{r simfun0}
set.seed(101)
t0 <- system.time(
  tt0 <- tabfun(n=17, nsim =  10000)
)
pow1_sim <- sum(tt0[1:3])
stopifnot(all.equal(pow1_sim, tt$power, tolerance = 2e-3))
print(tt0)
```

We confirm that we do get overall power, i.e. all outcomes with a clear sign, very close to the nominal value (`r round(pow1_sim, 3)`)

If the true effect size ($\delta = 1$) is equal to the cutoff/SESOI ($s=1$) then everything converges
to a narrow window around the SESOI: mostly "unclear magnitude/clear sign"
but always a clear sign. Indeed, we can see that for $n=100$ we have converged (for 95% CI/$\alpha = 0.05$) to all "clear sign" (i.e. power $\approx$ 100%) with 95% in the "unclear magnitude" category and 2.5% in "clearly small" or "clearly large".

```{r mm_tail}
tt1 <- tabfun(n=200, nsim = 10000)
print(tt1)
```

### Simulations with $\delta=0.5$, $s=1$, varying $n$

```{r sim1-plot, fig.width = 8}
sim1 <- readRDS("sim_sesoi_batch1.rds")
printfun(f_lengthen(sim1))
```

### Simulations with $\delta=1.5$, $s=1$, varying $n$

What if we make the true effect size greater than the SESOI?

```{r sim2-plot, fig.width = 8}
sim2 <- readRDS("sim_sesoi_batch2.rds")
printfun(f_lengthen(mm2))
```

## next steps

* Shiny app?
* add 'total power' (i.e. sum of all 'clear sign' outcomes) to plots?
* other examples?
* it would be elegant and computationally efficient to figure out the analytical results for this (i.e., probably in terms of non-central $\chi^2$ distributions - @owenSpecial1965 or @juliousSample2004 seem like useful starting points), although 10,000 simulations take only about `r round(t0[["elapsed"]], 2)` seconds (and could possibly be sped up a bit as well by eliminating overhead)
* change 'sign' to 'positive' in plots? (JD assumes a positive effect so the first plot can be labeled more clearly; maybe this is worth carrying forward)

## session info

```{r si}
sessionInfo()
```

## references
